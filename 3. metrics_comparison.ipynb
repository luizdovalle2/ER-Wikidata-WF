{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1227f63",
   "metadata": {},
   "source": [
    "# Evaluation of coverage outputs (best F2 / recall / threshold)\n",
    "\n",
    "## Purpose\n",
    "This notebook loads multiple saved *candidate-pair result files* (one per configuration/metric),\n",
    "evaluates them at several `match_count` thresholds, and produces a summary table with the\n",
    "**best F2**, **recall**, and the corresponding **threshold**, as reported in the article.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c989bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Ground-truth pairs (must contain: plLabel, alias, and index)\n",
    "GOLD_FILE = \"wd_dataset.parquet\"   # adjust if your gold is elsewhere\n",
    "\n",
    "# Saved result files: one per configuration (e.g., coverage_JW_0.2.parquet etc.)\n",
    "RESULTS_GLOB = \"coverage_outputs/*.parquet\"  # adjust path if needed\n",
    "\n",
    "# Thresholds to test (matching your previous loop: 0.5..1.0) (minimum coverage to be considered a match)\n",
    "THRESHOLDS = [t / 10 for t in range(5, 11)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5482eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold pairs: 991\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>name_variant</th>\n",
       "      <th>polish_label</th>\n",
       "      <th>alias_name_list</th>\n",
       "      <th>label_name_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q163043</td>\n",
       "      <td>Józefa Maria ks. Wettin</td>\n",
       "      <td>Maria Józefa Wettyn</td>\n",
       "      <td>[Wettin, ks., Maria, Józefa]</td>\n",
       "      <td>[Maria, Józefa, Wettyn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q163043</td>\n",
       "      <td>Maria Józefa Karolina Saska</td>\n",
       "      <td>Maria Józefa Wettyn</td>\n",
       "      <td>[Karolina, Maria, Saska, Józefa]</td>\n",
       "      <td>[Maria, Józefa, Wettyn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q25776</td>\n",
       "      <td>Владислав Юзеф Сапєга ч. Ліс</td>\n",
       "      <td>Władysław Jozafat Sapieha</td>\n",
       "      <td>[ч., Сапєга, Юзеф, Владислав, Ліс]</td>\n",
       "      <td>[Władysław, Sapieha, Jozafat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person                  name_variant               polish_label  \\\n",
       "0  Q163043       Józefa Maria ks. Wettin        Maria Józefa Wettyn   \n",
       "1  Q163043   Maria Józefa Karolina Saska        Maria Józefa Wettyn   \n",
       "2   Q25776  Владислав Юзеф Сапєга ч. Ліс  Władysław Jozafat Sapieha   \n",
       "\n",
       "                      alias_name_list                label_name_list  \n",
       "0        [Wettin, ks., Maria, Józefa]        [Maria, Józefa, Wettyn]  \n",
       "1    [Karolina, Maria, Saska, Józefa]        [Maria, Józefa, Wettyn]  \n",
       "2  [ч., Сапєга, Юзеф, Владислав, Ліс]  [Władysław, Sapieha, Jozafat]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gold = pd.read_parquet(GOLD_FILE)\n",
    "\n",
    "required_gold_cols = {\"polish_label\", \"name_variant\", \"person\"}\n",
    "missing = required_gold_cols - set(df_gold.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Gold file missing columns: {missing}\")\n",
    "\n",
    "# Gold set of true pairs for fast set operations\n",
    "gold_pairs = set(map(tuple, df_gold[[\"polish_label\", \"name_variant\"]].to_records(index=False)))\n",
    "\n",
    "print(\"Gold pairs:\", len(gold_pairs))\n",
    "df_gold.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4617389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(precision: float, recall: float, beta: float = 2.0) -> float:\n",
    "    \"\"\"\n",
    "    Compute F_beta score (weighted harmonic mean of precision and recall),  in this case default is f2\n",
    "    \"\"\"\n",
    "    if precision <= 0.0 and recall <= 0.0:\n",
    "        return 0.0\n",
    "    beta2 = beta * beta\n",
    "    denom = (beta2 * precision) + recall\n",
    "    return ((1 + beta2) * precision * recall / denom) if denom > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69dc505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_result_df(df_result: pd.DataFrame, gold_pairs: set, df_gold: pd.DataFrame, thresholds) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate a single result dataframe over multiple thresholds.\n",
    "\n",
    "    Returns a dataframe with one row per threshold containing:\n",
    "    precision, recall, f2, counts, retrieved amount, etc.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for thr in thresholds:\n",
    "        # Filter by coverage threshold\n",
    "        df_filt = df_result[df_result[\"coverage_value\"] >= thr]\n",
    "\n",
    "        # False negatives: gold indices not retrieved (same logic you used)\n",
    "        false_negative = df_gold[~df_gold[\"person\"].isin(df_filt[\"person\"])]\n",
    "        # Predicted pair set at this threshold\n",
    "        pred_pairs = set(map(tuple, df_filt[[\"polish_label\", \"name_variant\"]].to_records(index=False)))\n",
    "\n",
    "        # Set-based TP/FP\n",
    "        tp_set = pred_pairs & gold_pairs\n",
    "        fp_set = pred_pairs - gold_pairs\n",
    "\n",
    "        tp = len(tp_set)\n",
    "        fp = len(fp_set)\n",
    "        fn = len(false_negative)\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f2 = fbeta(precision, recall, beta=2.0)\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"threshold\": thr,\n",
    "                \"retrieved\": len(df_filt),\n",
    "                \"tp\": tp,\n",
    "                \"fp\": fp,\n",
    "                \"fn\": fn,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f2\": f2,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b5640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold  retrieved   tp      fp  fn  precision  recall        f2\n",
      "0        0.5     953209  955  520343   0   0.001832     1.0  0.009093\n",
      "1        0.6     802095  803  438536   0   0.001828     1.0  0.009072\n",
      "2        0.7     589510  606  323817   0   0.001868     1.0  0.009270\n",
      "3        0.8     561948  562  308491   0   0.001818     1.0  0.009027\n",
      "4        0.9     258296  287  141437   0   0.002025     1.0  0.010044\n",
      "5        1.0     257995  287  141231   0   0.002028     1.0  0.010058\n",
      "   threshold  retrieved   tp      fp  fn  precision  recall        f2\n",
      "0        0.5     949501  955  518265   0   0.001839     1.0  0.009129\n",
      "1        0.6     790668  802  432222   0   0.001852     1.0  0.009192\n",
      "2        0.7     575000  604  315982   0   0.001908     1.0  0.009467\n",
      "3        0.8     547496  559  300710   0   0.001855     1.0  0.009209\n",
      "4        0.9     248340  284  136103   0   0.002082     1.0  0.010326\n",
      "5        1.0     248051  284  135903   0   0.002085     1.0  0.010341\n"
     ]
    }
   ],
   "source": [
    "result_files = sorted(glob.glob(RESULTS_GLOB))\n",
    "if not result_files:\n",
    "    raise FileNotFoundError(f\"No files matched: {RESULTS_GLOB}\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "for path in result_files:\n",
    "    df_res = pd.read_parquet(path)\n",
    "\n",
    "    eval_table = evaluate_result_df(df_res, gold_pairs=gold_pairs, df_gold=df_gold, thresholds=THRESHOLDS)\n",
    "\n",
    "    # Select best threshold by F2 (ties broken by higher recall, then higher precision)\n",
    "    best = (\n",
    "        eval_table.sort_values([\"f2\", \"recall\", \"precision\"], ascending=False)\n",
    "        .iloc[0]\n",
    "        .to_dict()\n",
    "    )\n",
    "    print(eval_table)\n",
    "    summary_rows.append(\n",
    "        {\n",
    "            \"file\": os.path.basename(path),\n",
    "            \"best_threshold\": best[\"threshold\"],\n",
    "            \"precision\": best[\"precision\"],\n",
    "            \"recall\": best[\"recall\"],\n",
    "            \"f2\": best[\"f2\"],\n",
    "            \"retrieved\": int(best[\"retrieved\"]),\n",
    "            \"tp\": int(best[\"tp\"]),\n",
    "            \"fp\": int(best[\"fp\"]),\n",
    "            \"fn\": int(best[\"fn\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Export summary of best values\n",
    "df_summary = pd.DataFrame(summary_rows).sort_values([\"f2\", \"recall\"], ascending=False)\n",
    "df_summary.to_csv(\"summary_best_values.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6aef8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Union' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_phonetic_matched_frozensets2\u001b[39m(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     words: \u001b[43mUnion\u001b[49m[pd.Series, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m      3\u001b[39m     metric: Literal[\u001b[33m\"\u001b[39m\u001b[33mdm\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mdm\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m     ):\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    Build a set of matched token pairs using a phonetic algorithm, returned as\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    frozensets of indices (or labels), i.e. {frozenset({i, j}), ...}.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m      `frozenset({words[id_i], words[id_j]})`.\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Normalize input to a pandas Series so we can reliably keep stable identifiers.\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Union' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "variant_to_rows = defaultdict(set)\n",
    "for idx, variants in sets.items():\n",
    "    for variant in variants:\n",
    "        variant_to_rows[variant].add(idx)\n",
    "\n",
    "\n",
    "phonetic_matches_series = pd.Series({\n",
    "    idx: matching_rows(idx, variants, variant_to_rows)\n",
    "    for idx, variants in sets.items()\n",
    "}).dropna()\n",
    "phonetic_matches_list = phonetic_matches_series.explode().reset_index().apply(lambda x: set([x['index'], x[0]]), axis=1).to_list()\n",
    "matched_frozensets = set(frozenset(pair) for pair in phonetic_matches_list)\n",
    "print(len(matched_frozensets))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded15b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chex_env (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
