{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overview-cell",
   "metadata": {},
   "source": [
    "# Dataset Acquisition from Wikidata\n",
    "\n",
    "## Overview\n",
    "This notebook acquires entity reconciliation data from Wikidata for early modern Polish personal names.\n",
    "It retrieves pairs of main labels and alternative labels (aliases) for individuals who:\n",
    "- Have documented connections to Poland or its historical territories\n",
    "- Were active during 1264-1770 (early modern period)\n",
    "- Have multilingual name variants in Wikidata\n",
    "\n",
    "## Context\n",
    "The CHExRISH project at Jagiellonian University seeks to link historical records across multiple institutional databases.\n",
    "This dataset provides ground truth for evaluating entity reconciliation strategies on historical personal names.\n",
    "\n",
    "## Output\n",
    "A dataframe with ~6,000-7,000 label-alias pairs for benchmarking string similarity algorithms.\n",
    "Each row represents one person-name variant combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1-title",
   "metadata": {},
   "source": [
    "## Step 1: Query Wikidata SPARQL Endpoint\n",
    "\n",
    "This cell queries the Wikidata SPARQL endpoint to retrieve Polish personal names and their alternative labels.\n",
    "\n",
    "### Query Logic\n",
    "- **Entity type**: Humans (Q5)\n",
    "- **Polish connection**: Either in Polish Biographical Dictionary OR genealogical database \"The Great Genealogy\"\n",
    "- **Time period**: Born 1264-1770 (early modern era)\n",
    "- **Language**: Polish labels and aliases only\n",
    "- **Result**: Person ID, primary name label, alternative name label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acquire-wikidata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6960\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Wikidata SPARQL endpoint for querying structured data\n",
    "WIKIDATA_SPARQL_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# SPARQL query to retrieve Polish historical figures with alternative names\n",
    "# Two conditions for Polish connection (OR):\n    # 1. wdt:P8172 -> entry in Polish Biographical Dictionary\n",
    "    # 2. wdt:P1343 wd:Q1485141 -> mentioned in 'The Great Genealogy' reference\n",
    "wikidata_query = \"\"\"\n",
    "SELECT ?person ?polish_label ?name_variant\n",
    "WHERE {\n",
    "  {\n",
    "    ?person wdt:P31 wd:Q5 ;           # Human\n",
    "            wdt:P8172 ?pbd_key .      # In Polish Biographical Dictionary\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    ?person wdt:P31 wd:Q5 ;           # Human\n",
    "            wdt:P1343 wd:Q1485141 .   # Mentioned in 'The Great Genealogy'\n",
    "  }\n",
    "  \n",
    "  # Retrieve birth date, primary label, and alternative label\n",
    "  ?person wdt:P569 ?birth_date ;\n",
    "          rdfs:label ?polish_label ;\n",
    "          skos:altLabel ?name_variant .\n",
    "  \n",
    "  # Filter for Polish language labels and aliases\n",
    "  FILTER(LANG(?polish_label) = \"pl\")\n",
    "  FILTER(LANG(?name_variant) = \"pl\")\n",
    "  \n",
    "  # Filter for early modern period (1264-1770)\n",
    "  FILTER (?birth_date >= \"1264-01-01\"^^xsd:dateTime && \n",
    "          ?birth_date <= \"1770-12-31\"^^xsd:dateTime)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# HTTP headers for JSON response format\n",
    "request_headers = {\n",
    "    \"Accept\": \"application/sparql-results+json\"\n",
    "}\n",
    "\n",
    "# Execute the SPARQL query against Wikidata\n",
    "response = requests.get(\n",
    "    WIKIDATA_SPARQL_ENDPOINT,\n",
    "    params={\"query\": wikidata_query},\n",
    "    headers=request_headers\n",
    ")\n",
    "\n",
    "# Parse JSON response\n",
    "response_data = response.json()\n",
    "\n",
    "# Extract the bindings (actual result rows) from the response\n",
    "result_bindings = response_data[\"results\"][\"bindings\"]\n",
    "\n",
    "# Convert to pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(result_bindings)\n",
    "\n",
    "# Print initial count (may include duplicates)\n",
    "print(f\"Initial result count: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2-title",
   "metadata": {},
   "source": [
    "## Step 2: Extract and Clean Data\n",
    "\n",
    "This cell processes the raw Wikidata results:\n",
    "1. Extracts Wikidata IDs (Q-identifiers) from URIs\n",
    "2. Extracts the actual text values from nested JSON structures\n",
    "3. Removes duplicate label-alias pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "process-wikidata-results",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>person</td><td>name_variant</td><td>polish_label</td></tr></table>"
      ],
      "text/plain": [
       "   person             name_variant          polish_label\n",
       "0   Q96212877         Ludwik Sokolski      Ludwik Sokulski\n",
       "1   Q96212877         Ludwik Sokulski h. Abdank  Ludwik Sokulski\n",
       "2   Q203808          Bogdan Chmielnicki     Bohdan Chmielnicki\n",
       "..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Extract entity IDs from Wikidata URIs\n",
    "# ============================================================================\n",
    "# Wikidata returns URIs like \"http://www.wikidata.org/entity/Q96212877\"\n",
    "# We extract just the Q-identifier (e.g., \"Q96212877\")\n",
    "\n",
    "df[\"person\"] = df[\"person\"].apply(\n",
    "    lambda uri_dict: uri_dict['value'].split(\"/\")[-1]  # Get last part after final slash\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Extract text values from nested JSON structures\n",
    "# ============================================================================\n",
    "# Wikidata returns values as {\"value\": \"actual_text\", \"type\": \"literal\"}\n",
    "# We extract just the \"value\" field\n",
    "\n",
    "df[\"name_variant\"] = df[\"name_variant\"].apply(\n",
    "    lambda value_dict: value_dict['value']\n",
    ")\n",
    "\n",
    "df[\"polish_label\"] = df[\"polish_label\"].apply(\n",
    "    lambda value_dict: value_dict['value']\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Remove duplicate label-alias pairs\n",
    "# ============================================================================\n",
    "# Wikidata may return the same person-name combination multiple times\n",
    "# Keep only unique pairs\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f\"Final deduplicated count: {len(df)}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Display example name variations showing why entity reconciliation is needed\n",
    "print(f\"\\n=== Examples of Name Variations ===\")\n",
    "print(f\"Person Q203808 variations:\")\n",
    "print(df[df['person'] == 'Q203808'][['polish_label', 'name_variant']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3-title",
   "metadata": {},
   "source": [
    "## Step 3: Summary Statistics\n",
    "\n",
    "Analyze the acquired dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dataset-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Dataset Overview\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"=== DATASET STATISTICS ===\")\n",
    "print(f\"Total label-alias pairs: {len(df)}\")\n",
    "print(f\"Unique Wikidata entities: {df['person'].nunique()}\")\n",
    "print(f\"\\nDataset structure:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\n=== Example Records ===\")\n",
    "print(f\"\\nSample of 5 random pairs:\")\n",
    "print(df.sample(5))\n",
    "\n",
    "# ============================================================================\n",
    "# Name Complexity Analysis\n",
    "# ============================================================================\n",
    "# Analyze number of name components (words) in labels vs variants\n",
    "\n",
    "df[\"label_num_components\"] = df[\"polish_label\"].str.split().str.len()\n",
    "df[\"variant_num_components\"] = df[\"name_variant\"].str.split().str.len()\n",
    "\n",
    "print(f\"\\n=== Name Complexity ===\")\n",
    "print(f\"Primary label - Average components: {df['label_num_components'].mean():.2f}\")\n",
    "print(f\"Primary label - Components range: {df['label_num_components'].min()}-{df['label_num_components'].max()}\")\n",
    "print(f\"\\nAlternative variant - Average components: {df['variant_num_components'].mean():.2f}\")\n",
    "print(f\"Alternative variant - Components range: {df['variant_num_components'].min()}-{df['variant_num_components'].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}